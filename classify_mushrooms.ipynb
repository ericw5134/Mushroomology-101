{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisonous Mushroom Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from scipy.stats import chi2_contingency\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "# Outlier Analysis\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFE, SelectKBest, mutual_info_classif\n",
    "# Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# Metrics\n",
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "D = pd.read_csv('secondary_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Z-score Upper/Lower Bound outilers\n",
    "num_data = D.describe()\n",
    "z_score_outlier_threshold = 3\n",
    "for column in num_data:\n",
    "    mean = num_data[column]['mean']\n",
    "    std = num_data[column]['std']\n",
    "    ub = mean + z_score_outlier_threshold * std\n",
    "    lb = mean - z_score_outlier_threshold * std\n",
    "    \n",
    "    num_outliers = len(D[(D[column] < lb) | (D[column] > ub)])\n",
    "    \n",
    "    if lb < 0:\n",
    "        lb = 'N/A'\n",
    "    print(f'{column} Z-score Outlier Count: {num_outliers}, Lower Bound: {lb}, Upper Bound: {ub}')\n",
    "    \n",
    "# Compute IQR Upper/Lower Bound outliers\n",
    "num_columns = D[num_data.columns].copy()\n",
    "Q1 = num_columns.quantile(.25)\n",
    "Q3 = num_columns.quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "UB = Q3 + 1.5 * IQR\n",
    "LB = Q1 - 1.5 * IQR\n",
    "for column in num_columns:\n",
    "    lb = LB[column]\n",
    "    ub = UB[column]\n",
    "    \n",
    "    num_outliers = len(D[(D[column] < lb) | (D[column] > ub)])\n",
    "    \n",
    "    if lb < 0:\n",
    "        lb = 'N/A'\n",
    "    \n",
    "    print(f'{column} IQR Outlier Count: {num_outliers}, Lower Bound: {lb}, Upper Bound: {ub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of each attribute\n",
    "# Set size of plots for each histogram\n",
    "fig, axs = plt.subplots(nrows=3, ncols=7, figsize=(28, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Count number of missing data points for each feature\n",
    "nan_count = D.isna().sum()\n",
    "\n",
    "for i, column in enumerate(D.columns):\n",
    "    # Plot the histogram\n",
    "    sns.histplot(D[column], ax=axs[i], bins=50)\n",
    "    \n",
    "    # Display missing values\n",
    "    missing_value_count = f\"Missing value count: {nan_count[column]}\"\n",
    "    axs[i].text(.985, 0.985, missing_value_count, transform=axs[i].transAxes, ha=\"right\", va=\"top\", \n",
    "                 fontsize=10, color='red', bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.3'))\n",
    "    \n",
    "    # Set titles and labels\n",
    "    axs[i].set_title(f'Histogram of {column}')\n",
    "    axs[i].set_xlabel(column)\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "\n",
    "# Display histograms\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots of each numerical attribute\n",
    "# Set size of plots for each boxplot\n",
    "numerical_data = D[D.select_dtypes(include=['number']).columns]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, column in enumerate(numerical_data.columns):\n",
    "    # Plot the boxplot for the numeric column\n",
    "    sns.boxplot(x=D[column], ax=axs[i])\n",
    "\n",
    "    # Set titles and labels\n",
    "    axs[i].set_title(f'Box Plot of {column}')\n",
    "    axs[i].set_xlabel(column)\n",
    "    axs[i].set_ylabel('Values')\n",
    "    \n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmaps to visualize relationships and identify correlations\n",
    "# https://stackoverflow.com/questions/46498455/categorical-features-correlation\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    if min((kcorr-1), (rcorr-1)) == 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "num_corr_mat = numerical_data.corr()\n",
    "\n",
    "plt.figure(figure=(8,6))\n",
    "sns.heatmap(num_corr_mat, annot=True)\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Correlation Heatmap of Numerical Attributes')\n",
    "plt.show()\n",
    "\n",
    "categorical_data = D[D.select_dtypes(include=['object']).columns]\n",
    "categorical_corr_mat = pd.DataFrame(np.zeros((len(categorical_data.columns), len(categorical_data.columns))),\n",
    "                                columns=categorical_data.columns, index=categorical_data.columns)\n",
    "\n",
    "for x in categorical_data.columns:\n",
    "    for y in categorical_data.columns:\n",
    "        if x == 1:\n",
    "            categorical_corr_mat[x, y] = 1\n",
    "        else:\n",
    "            cat_confusion_matrix = pd.crosstab(categorical_data[x], categorical_data[y])\n",
    "            categorical_corr_mat.loc[x, y] = cramers_v(cat_confusion_matrix.values)\n",
    "plt.figure(figure=(20,20))\n",
    "sns.heatmap(categorical_corr_mat)\n",
    "plt.title('Correlation Heatmap of Categorical Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features which are mostly NaN\n",
    "drop_threshold = len(D) / 2\n",
    "D_dropped_na = D.dropna(axis=1, thresh=drop_threshold)\n",
    "print(D.drop(columns=D_dropped_na.columns))\n",
    "\n",
    "# Split data into training(80%)/testing(20%) data\n",
    "X = D_dropped_na.drop(columns='class')\n",
    "y = D_dropped_na['class'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical/categorical feature mask\n",
    "numerical_mask = X_train.select_dtypes(include=['number']).columns\n",
    "categorical_mask = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply preprocessing steps to numerical features\n",
    "        ('num', Pipeline(steps=[\n",
    "                    # No missing numerical samples\n",
    "                    # Apply Z-Score standardization\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    # Only 3 numerical features, no need to apply PCA\n",
    "                ]), numerical_mask),\n",
    "        # Apply preprocessing steps to categorical features\n",
    "        ('cat', Pipeline(steps=[\n",
    "                    # Impute categorical data by mode\n",
    "                    ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "                    # Encode categorical data using OneHotEncoding\n",
    "                    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "                ]), categorical_mask),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate preprocessed data using preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "    ])\n",
    "X_train_prep = pd.DataFrame(preprocessing_pipeline.fit_transform(X_train))\n",
    "X_test_prep = pd.DataFrame(preprocessing_pipeline.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve column names\n",
    "numerical_columns = numerical_mask\n",
    "categorical_columns = preprocessing_pipeline.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_mask)\n",
    "all_column_names = np.concatenate([numerical_columns, categorical_columns])\n",
    "X_train_prep.columns = all_column_names\n",
    "X_test_prep.columns = all_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate clusters using various scores\n",
    "def evaluate_clusters(X, labels):\n",
    "    sil_score = silhouette_score(X, labels)\n",
    "    ch_score = calinski_harabasz_score(X, labels)\n",
    "    db_score = davies_bouldin_score(X, labels)\n",
    "    return sil_score, ch_score, db_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "def visualize_clusters(X_pca, labels, algorithm):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels)\n",
    "    plt.title(f\"Clustering using {algorithm}\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit clustering algorithms on training data\n",
    "X_cluster = X_train_prep.copy()\n",
    "\n",
    "# Reduce dimensionality to visualize clusters\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KMeans Clustering\n",
    "\n",
    "# Find the best number of clusters for KMeans\n",
    "def find_best_kmeans(X, min_clusters=2, max_clusters=10):\n",
    "    best_n_clusters = min_clusters\n",
    "    best_scores = {'silhouette': -1, 'calinski_harabasz': -1, 'davies_bouldin': float('inf')}\n",
    "    best_labels = None\n",
    "\n",
    "    for n_clusters in range(min_clusters, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=42).fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        sil_score, ch_score, db_score = evaluate_clusters(X, labels)\n",
    "\n",
    "        # Update if scores are better\n",
    "        if sil_score > best_scores['silhouette']:\n",
    "            best_scores = {'silhouette': sil_score, 'calinski_harabasz': ch_score, 'davies_bouldin': db_score}\n",
    "            best_n_clusters = n_clusters\n",
    "            best_labels = labels\n",
    "\n",
    "    return best_n_clusters, best_scores, best_labels\n",
    "\n",
    "best_n_clusters, best_scores, best_labels = find_best_kmeans(X_cluster)\n",
    "print(f\"Best KMeans Clusters: {best_n_clusters}\")\n",
    "print(f\"Silhouette Score: {best_scores['silhouette']:.4f}\")\n",
    "print(f\"Calinski Harabasz Score: {best_scores['calinski_harabasz']:.4f}\")\n",
    "print(f\"Davies Bouldin Score: {best_scores['davies_bouldin']:.4f}\")\n",
    "\n",
    "visualize_clusters(X_pca, best_labels, f'KMeans (n_clusters={best_n_clusters})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=3, min_samples=2).fit(X_cluster)\n",
    "sil_score, ch_score, db_score = evaluate_clusters(X_cluster, dbscan.labels_)\n",
    "print(\"\\nDBSCAN Clustering:\")\n",
    "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "print(f\"Calinski Harabasz Score: {ch_score:.4f}\")\n",
    "print(f\"Davies Bouldin Score: {db_score:.4f}\")\n",
    "visualize_clusters(X_pca, dbscan.labels_, 'DBSCAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate clusters using various scores\n",
    "def evaluate_clusters(X, labels):\n",
    "    sil_score = silhouette_score(X, labels)\n",
    "    ch_score = calinski_harabasz_score(X, labels)\n",
    "    db_score = davies_bouldin_score(X, labels)\n",
    "    print('Silhouette Score: %1.4f' % sil_score)\n",
    "    print('Calinski Harabasz Score: %1.4f' % ch_score)\n",
    "    print('Davies Bouldin Score: %1.4f' % db_score)\n",
    "\n",
    "# Agglomerative clustering can only handle small datasets\n",
    "# Sample from training data\n",
    "X_agg_sample = X_cluster.sample(n=5000)\n",
    "agg = AgglomerativeClustering().fit(X_agg_sample)\n",
    "evaluate_clusters(X_agg_sample, agg.labels_)\n",
    "X_agg_pca = pca.transform(X_agg_sample)\n",
    "visualize_clusters(X_agg_pca, agg.labels_, 'Agglomerative Clustering')\n",
    "\n",
    "# Visualize Dendrogram for Agglomerative Clustering\n",
    "# https://www.geeksforgeeks.org/hierarchical-clustering-with-scikit-learn/\n",
    "Z = linkage(X_agg_pca, method='ward')\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Outliers\n",
    "def visualize_outliers(X_pca, outliers, model):\n",
    "    X_outliers = X_pca[outliers == -1]\n",
    "    X_inliers = X_pca[outliers == 1]\n",
    "    x_out, y_out = X_outliers[:, 0], X_outliers[:, 1]\n",
    "    x_in, y_in = X_inliers[:, 0], X_inliers[:, 1]\n",
    "    \n",
    "    # Plot the outliers and inliers\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(x_in, y_in, label='Inliers', color='blue')\n",
    "    plt.scatter(x_out, y_out, label='Outliers', color='red')\n",
    "    plt.title(f'Outliers Detected by {model}')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Outlier Detection algorithms on train dataset\n",
    "X_outliers = X_train_prep.copy()\n",
    "\n",
    "# Reduce dimensionality to visualize clusters\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "iso_outliers = IsolationForest(random_state=0).fit_predict(X_outliers)\n",
    "visualize_outliers(X_pca, iso_outliers, 'Isolation Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LocalOutlierFactor\n",
    "lof_outliers = LocalOutlierFactor().fit_predict(X_outliers)\n",
    "visualize_outliers(X_pca, lof_outliers, 'LocalOutlierFactor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EllipticEnvelope\n",
    "env_outliers = EllipticEnvelope(random_state=0).fit_predict(X_outliers)\n",
    "visualize_outliers(X_pca, env_outliers, 'EllipticEnvelope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_consistency(X_train, y_train, model):\n",
    "    # Perform cross-validation to evaluate model consistency\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"Mean Cross-validation Scores: \", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only RandomForest, GaussianNB, and LogisticRegression imported\n",
    "def train_model(X_train, X_test, y_train, y_test, model):\n",
    "    # Measure time to train/predict\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fit model and predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    model_time = end_time - start_time\n",
    "    \n",
    "    # Get class probability for roc_auc_score/roc_curve\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_pred, y_prob, model_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, y_pred, y_prob, runtime):\n",
    "    # Output various scores to evaluate model\n",
    "    print(\"Model train and predict time: %1.4f\" % runtime)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"AUC-ROC Score: %1.4f\" % roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(y_test, y_pred, y_prob, model):\n",
    "    # Plot confusion matrix\n",
    "    labels = ['e', 'p']\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model} Confusion Matrix')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ROC Curve\n",
    "    # https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob, pos_label='p')\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.title(f'{model} Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, label=f'AUC = %1.4f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline for a model\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, model):\n",
    "    evaluate_model_consistency(X_train, y_train, model)\n",
    "    y_pred, y_prob, runtime = train_model(X_train, X_test, y_train, y_test, model)\n",
    "    evaluate_model(y_test, y_pred, y_prob, runtime)\n",
    "    visualize_results(y_test, y_pred, y_prob, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View feature importance using LogisticRegression coefficients\n",
    "def visualize_feature_importance(coeffs, X, model):\n",
    "    importance_df = pd.DataFrame()\n",
    "    importance_df['Feature'] = X.columns\n",
    "    importance_df['Coefficient'] = np.abs(coeffs)\n",
    "\n",
    "    importance_df = importance_df.sort_values(by='Coefficient', ascending=False)\n",
    "    plt.barh(importance_df['Feature'], importance_df['Coefficient'])\n",
    "    plt.xlabel('Importance as Absolute Value of Coefficients')\n",
    "    plt.title(f'Feature Importance of LogisticRegression using {model}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate classification model without Feature Selection\n",
    "# Use LogisticRegression as model\n",
    "X_train_fe = X_train_prep.copy()\n",
    "X_test_fe = X_test_prep.copy()\n",
    "clf = LogisticRegression(max_iter=10000, random_state=0)\n",
    "train_and_evaluate_model(X_train_fe, X_test_fe, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit train dataset on RecursiveFeatureSelection\n",
    "rfe = RFE(clf, n_features_to_select=25).fit(X_train_fe, y_train)\n",
    "X_train_rfe = X_train_fe.loc[:, rfe.support_]\n",
    "X_test_rfe = X_test_fe.loc[:, rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View selected columns from RFE\n",
    "X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate classification model with Feature Selection\n",
    "train_and_evaluate_model(X_train_rfe, X_test_rfe, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance after RFE\n",
    "coeffs = clf.coef_[0]\n",
    "visualize_feature_importance(coeffs, X_train_rfe, 'Recursive Feature Elimination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the k best features based on MutualInformation\n",
    "k_best = SelectKBest(mutual_info_classif, k=25)\n",
    "X_train_mi = k_best.fit(X_train_fe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform train and test data on selected features\n",
    "k_best_support = X_train_fe.columns[k_best.get_support(indices=True)]\n",
    "X_train_mi = X_train_fe.loc[:, k_best_support]\n",
    "X_test_mi = X_test_fe.loc[:, k_best_support]\n",
    "k_best_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate classification model with mutual information\n",
    "train_and_evaluate_model(X_train_mi, X_test_mi, y_train, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance after mutual information\n",
    "coeffs = clf.coef_[0]\n",
    "visualize_feature_importance(coeffs, X_train_mi, 'Mutual Information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate classification models\n",
    "# Using GaussianNB, RandomForests, and LogisticRegression\n",
    "X_train_classify = X_train_rfe.copy()\n",
    "X_test_classify = X_test_rfe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB\n",
    "gnb = GaussianNB()\n",
    "train_and_evaluate_model(X_train_classify, X_test_classify, y_train, y_test, gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RandomForestClassified\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "train_and_evaluate_model(X_train_classify, X_test_classify, y_train, y_test, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "logr = LogisticRegression(max_iter=10000, random_state=0)\n",
    "train_and_evaluate_model(X_train_classify, X_test_classify, y_train, y_test, logr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning using Grid Search on LogisticRegrssion\n",
    "X_train_hyper = X_train_rfe.copy()\n",
    "X_test_hyper = X_test_rfe.copy()\n",
    "logr = LogisticRegression(max_iter=10000, random_state=0)\n",
    "\n",
    "# Define grid search parameters\n",
    "param_grid = {\n",
    "    'C': [.0001, .001, .01, .1, 1, 10],\n",
    "    'tol': [.00001, .0001, .001, .01 , .1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the training data on GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=logr, param_grid=param_grid, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train_hyper, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results from GridSearch\n",
    "gs_results = grid_search.cv_results_\n",
    "\n",
    "for tol in param_grid['tol']:\n",
    "    tol_mask = gs_results['param_tol'] == tol\n",
    "    plt.plot(gs_results['param_C'][tol_mask], gs_results['mean_test_score'][tol_mask], label=tol, marker='o')\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.title('Accuracy vs C Accross Different Tolerence')\n",
    "plt.xlabel('C (Inverse of regularization strength)')\n",
    "plt.ylabel('Mean Cross-Validation Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using best params from GridSearch\n",
    "C = grid_search.best_params_['C']\n",
    "tol = grid_search.best_params_['tol']\n",
    "print(f\"Optimal C: {C}\")\n",
    "print(f\"Optimal tol: {tol}\")\n",
    "\n",
    "logr_gs = LogisticRegression(C=C, tol=tol, max_iter=10000, random_state=0)\n",
    "train_and_evaluate_model(X_train_hyper, X_test_hyper, y_train, y_test, logr_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning using RandomSearch on RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "\n",
    "# Define Random Search parameters\n",
    "param_dists = {\n",
    "    'n_estimators': [50, 100, 250, 500],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [2, 5, 10, 25, 50, 100, None],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the training data on RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rfc, param_distributions=param_dists, n_iter=50, scoring='accuracy', verbose=2, random_state=0)\n",
    "random_search.fit(X_train_hyper, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using best params from RandomizedSerach\n",
    "n_estimators = random_search.best_params_['n_estimators']\n",
    "min_samples_split = random_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = random_search.best_params_['min_samples_leaf']\n",
    "max_features = random_search.best_params_['max_features']\n",
    "max_depth = random_search.best_params_['max_depth']\n",
    "criterion = random_search.best_params_['criterion']\n",
    "\n",
    "for param in random_search.best_params_:\n",
    "    print(f\"Optimal {param}: {random_search.best_params_[param]}\")\n",
    "\n",
    "rfc_rs = RandomForestClassifier(n_estimators=n_estimators, min_samples_split=min_samples_split\n",
    "                                , min_samples_leaf=min_samples_leaf, max_features=max_features,\n",
    "                                max_depth=max_depth, criterion=criterion, random_state=0)\n",
    "train_and_evaluate_model(X_train_hyper, X_test_hyper, y_train, y_test, rfc_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
